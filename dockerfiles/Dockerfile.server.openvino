#-------------------------------------------------------------------------
# Copyright(C) 2019 Intel Corporation.
# Licensed under the MIT License.
#--------------------------------------------------------------------------

FROM ubuntu:16.04 as build

RUN apt update && \
    apt -y install git sudo wget \
    zip x11-apps lsb-core cpio libboost-python-dev libpng-dev zlib1g-dev libnuma1 ocl-icd-libopencl1 clinfo libboost-filesystem1.58.0 libboost-thread1.58.0 protobuf-compiler libprotoc-dev libusb-1.0-0-dev

ARG DEVICE=CPU_FP32
ARG ONNXRUNTIME_REPO=https://github.com/microsoft/onnxruntime
ARG ONNXRUNTIME_BRANCH=master

WORKDIR /code
ENV PATH /opt/miniconda/bin:/code/cmake-3.14.3-Linux-x86_64/bin:$PATH

RUN git clone --recursive -b $ONNXRUNTIME_BRANCH $ONNXRUNTIME_REPO onnxruntime && \
    cp onnxruntime/docs/Privacy.md /code/Privacy.md && \
    cp onnxruntime/dockerfiles/LICENSE-IMAGE.txt /code/LICENSE-IMAGE.txt && \
    cp onnxruntime/ThirdPartyNotices.txt /code/ThirdPartyNotices.txt

RUN /bin/sh onnxruntime/dockerfiles/scripts/install_common_deps.sh && \
    /bin/bash onnxruntime/tools/ci_build/github/linux/docker/scripts/install_server_deps.sh && \
    cd onnxruntime/cmake/external/onnx && python3 setup.py install

RUN pip install azure-iothub-device-client azure-iothub-service-client azure-iot-provisioning-device-client

ENV pattern="COMPONENTS=DEFAULTS"
ENV replacement="COMPONENTS=intel-openvino-ie-sdk-ubuntu-xenial__x86_64;intel-openvino-ie-rt-cpu-ubuntu-xenial__x86_64;intel-openvino-ie-rt-gpu-ubuntu-xenial__x86_64;intel-openvino-ie-rt-vpu-ubuntu-xenial__x86_64;intel-openvino-ie-rt-hddl-ubuntu-xenial__x86_64;intel-openvino-model-optimizer__x86_64;intel-openvino-opencv-lib-ubuntu-xenial__x86_64"
COPY l_openvino_*.tgz .
RUN tar -xzf l_openvino_toolkit*.tgz && \
    rm -rf l_openvino_toolkit*.tgz && \
    cd l_openvino_toolkit* && \
    sed -i "s/$pattern/$replacement/" silent.cfg && \
    sed -i 's/decline/accept/g' silent.cfg && \
    ./install.sh -s silent.cfg && \
    cd - && \
    rm -rf l_openvino_toolkit* && \
    cd /opt/intel/openvino/install_dependencies && ./_install_all_dependencies.sh && dpkg -i *.deb && \
    pip install networkx==2.3 test-generator==0.1.1 defusedxml>=0.5.0

ENV LD_LIBRARY_PATH=/opt/miniconda/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
ENV INTEL_OPENVINO_DIR=/opt/intel/openvino_2019.1.144
ENV INTEL_CVSDK_DIR=/opt/intel/openvino_2019.1.144
ENV IE_PLUGINS_PATH=${INTEL_CVSDK_DIR}/deployment_tools/inference_engine/lib/intel64
ENV LD_LIBRARY_PATH=/opt/intel/opencl:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/cldnn/lib:${INTEL_OPENVINO_DIR}/inference_engine/external/gna/lib:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/mkltiny_lnx/lib:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/omp/lib:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/tbb/lib:${IE_PLUGINS_PATH}:${LD_LIBRARY_PATH}
ENV OpenCV_DIR=${INTEL_OPENVINO_DIR}/opencv/share/OpenCV
ENV LD_LIBRARY_PATH=${INTEL_OPENVINO_DIR}/opencv/lib:${INTEL_OPENVINO_DIR}/opencv/share/OpenCV/3rdparty/lib:${LD_LIBRARY_PATH}
ENV PATH=${INTEL_CVSDK_DIR}/deployment_tools/model_optimizer:$PATH
ENV PYTHONPATH=${INTEL_CVSDK_DIR}/deployment_tools/model_optimizer:$PYTHONPATH
ENV HDDL_INSTALL_DIR=${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/hddl
ENV LD_LIBRARY_PATH=${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/hddl/lib:$LD_LIBRARY_PATH
ENV PATH="/usr/local/go/bin:${PATH}"
ENV LANG en_US.UTF-8

RUN cd onnxruntime && ./build.sh --config RelWithDebInfo --update --build --parallel --use_openvino $DEVICE --build_server


From ubuntu:16.04
WORKDIR /onnxruntime/server/
COPY --from=build /code/onnxruntime/build/Linux/RelWithDebInfo/onnxruntime_server  /onnxruntime/server/
COPY --from=build /code/onnxruntime/build/Linux/RelWithDebInfo/libonnxruntime.so.* /lib/
COPY --from=build /opt/miniconda/lib/*.so* /lib/
COPY --from=build /opt/intel/openvino_*/deployment_tools/inference_engine/lib/intel64/*.so* /lib/
COPY --from=build /opt/intel/openvino_2019.1.144/deployment_tools/inference_engine/external/tbb/lib/libtbb*so* /lib/
ENTRYPOINT ["/onnxruntime/server/onnxruntime_server"]
